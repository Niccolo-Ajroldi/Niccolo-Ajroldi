
<!---
<img src="https://github.com/Niccolo-Ajroldi/Functional-Autoregressive-Process-2D/blob/main/Yt.gif" width="500" />
-->
 
I like ML, in particular deep learning optimization, efficency and benchmarks! 

[Here](https://github.com/Niccolo-Ajroldi/Niccolo-Ajroldi/blob/main/Niccolo_Ajroldi_CV.pdf) you can find a copy of my CV.

You can find me also on:
<p align="left">
<a href="https://twitter.com/n_ajroldi" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/twitter.svg" alt="Niccolo-Ajroldi" height="30" width="40" /></a>
<a href="https://www.linkedin.com/in/niccol%C3%B2-ajroldi-67653b196/" target="blank"><img align="center" src="https://raw.githubusercontent.com/rahuldkjain/github-profile-readme-generator/master/src/images/icons/Social/linked-in-alt.svg" alt="Niccolo-Ajroldi" height="30" width="40" /></a>
<a href="https://www.strava.com/athletes/58042546" target="blank"><img align="center" src="https://cdn.worldvectorlogo.com/logos/strava-2.svg" alt="Niccolo-Ajroldi" height="30" width="40" /></a>

<!---
<a href="https://stackoverflow.com/users/12200819/niccol%c3%b2-ajroldi" target="blank"><img align="center" src="https://upload.wikimedia.org/wikipedia/commons/e/ef/Stack_Overflow_icon.svg" alt="Niccolo-Ajroldi" height="30" width="40" /></a>
<a href="https://math.stackexchange.com/users/713731/niccol%c3%b2-ajroldi" target="blank"><img align="center" src="https://cdn.sstatic.net/Sites/math/Img/apple-touch-icon.png?v=0ae50baa40ed" alt="Niccolo-Ajroldi" height="30" width="40" /></a>
-->

## Highlights
- *March, 2025*. üìÑ Our [paper](https://arxiv.org/abs/2502.06761) on Weight Averaging has been accepted at the ICLR 2025 First [Workshop](https://open-foundation-model.github.io/) on Open Science for Foundation Models!
- *February, 2025*. üó£Ô∏è Gave my first talk! Presented our work on Weight Averaging for large scale ML at the First [AlgoPerf Workshop](https://algoperf-workshop.github.io/).
- *October, 2024*. üìÑ Our paper on [Loss Landscape Characterization of Neural Networks without Over-Parametrization](https://arxiv.org/abs/2410.12455) has been accepted to NeurIPS 2024!
- *August, 2024*. :tada: Our submission to AlgoPerf scored third :3rd_place_medal: in the [inaugural benchmark results](https://mlcommons.org/2024/08/mlc-algoperf-benchmark-competition/)! We scored first among non-industry submissions! Checkout the MLCommons [blogpost](https://mlcommons.org/benchmarks/algorithms/) and our submissions in the official [repo](https://github.com/mlcommons/algorithms_results_v0.5/tree/main/AlgoPerf_Team_25).
- *July, 2024*. :open_file_folder: Released [plainLM](https://github.com/Niccolo-Ajroldi/plainLM), a minimal open-source repository for pre-training Transformers on Language Modeling. It is written in PyTorch, supports distributed training, and contains a minimal Transformer implementation, with RoPE, RMSNorm, GLU.

## Publications
[**Loss Landscape Characterization of Neural Networks without Over-Parametrization**](https://www.sciencedirect.com/science/article/pii/S0167947323001329?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=263311102&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM391842&utm_source=AC_) <br />
*Islamov, **Ajroldi**, Orvieto, Lucchi*, to appear in *Advances in Neural Information Processing Systems 2024 (NeurIPS 2024)* <br /> 
We introduce a new function class that better captures neural network loss landscapes, ensuring convergence for several SGD-based algorithms, and showing its applicability across several Deep Learning tasks!

[**Conformal Prediction Bands for Two-Dimensional Functional Time Series**](https://www.sciencedirect.com/science/article/pii/S0167947323001329?utm_campaign=STMJ_AUTH_SERV_PUBLISHED&utm_medium=email&utm_acid=263311102&SIS_ID=&dgcid=STMJ_AUTH_SERV_PUBLISHED&CMX_ID=&utm_in=DM391842&utm_source=AC_) <br /> 
***Ajroldi**, Diquigiovanni, Fontana, Vantini, *Computational Statistics & Data Analysis*, 2023.* <br /> 
We develop algorithms to forecast time evolving surfaces and estimate prediction uncertainty. We introduce estimation techniques for functional autoregressive models and revisit distribution-free uncertainty quantification techniques for this setting.

[**Continuous and early prediction of Acute Kidney Injury in critically ill patients**](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0287398) <br /> 
*Alfieri, Ancona, Tripepi, Rubeis, **Ajroldi**, Finazzi, Cauda, Fagugli, (2023), on PLOS ONE.* <br /> 
We propose a novel ML model to continuosly predict Acute Kidney Injury episodes in Intensive Care Units using routinely-available data. The model is tested through a multi-centric, multi-national external validation procedure.
